# Lit Review


##TODO

@article{Prakken2012-PRARPV,
  journal = {Artificial Intelligence and Law},
  volume = {20},
  author = {Henry Prakken},
  title = {Reconstructing Popov V. Hayashi in a Framework for Argumentation with Structured Arguments and Dungean Semantics},
  pages = {57--82},
  number = {1},
  year = {2012}
}

> In this article the argumentation structure of the court’s decision in the Popov v. Hayashi case is formalised in Prakken’s (Argument Comput 1:93–124; 2010) abstract framework for argument-based inference with structured arguments. In this framework, arguments are inference trees formed by applying two kinds of inference rules, strict and defeasible rules. Arguments can be attacked in three ways: attacking a premise, attacking a conclusion and attacking an inference. To resolve such conflicts, preferences may be used, which leads to three corresponding kinds of defeat, after which Dung’s (Artif Intell 77:321–357; 1995) abstract acceptability semantics can be used to evaluate the arguments. In the present paper the abstract framework is instantiated with strict inference rules corresponding to first-order logic and with defeasible inference rules for defeasible modus ponens and various argument schemes. The main techniques used in the formal reconstruction of the case are rule-exception structures and arguments about rule validity. Arguments about socio-legal values and the use of precedent cases are reduced to arguments about rule validity. The tree structure of arguments, with explicit subargument relations between arguments, is used to capture the dependency relations between the elements of the court’s decision 



@article{Brey2005-BRETEA,
  pages = {383--398},
  number = {3-4},
  author = {Philip Brey},
  publisher = {Springer},
  year = {2005},
  volume = {15},
  journal = {Minds and Machines},
  title = {The Epistemology and Ontology of Human-Computer Interaction}
}

> This paper analyzes epistemological and ontological dimensions of Human-Computer Interaction (HCI) through an analysis of the functions of computer systems in relation to their users. It is argued that the primary relation between humans and computer systems has historically been epistemic: computers are used as information-processing and problem-solving tools that extend human cognition, thereby creating hybrid cognitive systems consisting of a human processor and an artificial processor that process information in tandem. In this role, computer systems extend human cognition. Next, it is argued that in recent years, the epistemic relation between humans and computers has been supplemented by an ontic relation. Current computer systems are able to simulate virtual and social environments that extend the interactive possibilities found in the physical environment. This type of relationship is primarily ontic, and extends to objects and places that have a virtual ontology. Increasingly, computers are not just information devices, but portals to worlds that we inhabit. The aforementioned epistemic and ontic relationships are unique to information technology and distinguish human-computer relationships from other human-technology relationships. 

@article{zollman2015modeling,
  title={Modeling the social consequences of testimonial norms},
  author={Zollman, Kevin JS},
  journal={Philosophical Studies},
  volume={172},
  number={9},
  pages={2371--2383},
  year={2015},
  publisher={Springer}
}


> This paper approaches the problem of testimony from a new direction. Rather  than  focusing  on  the  epistemic  grounds  for  testimony,  it  considers  the problem from the perspective of an individual who must choose whom to trust from a population of many would-be testifiers. A computer simulation is presented which illustrates that in many plausible situations, those who trust without attempting to judge the reliability of testifiers outperform those who attempt to seek out the more reliable members of the community. In so doing, it presents a novel defense for the credulist  position  that  argues  one  should  trust  testimony  without  considering  the underlying reliability of the testifier.


@article{David2004-DAVTSA-16,
  author = {Nuno David and Maria Marietto and Jaime Sichman and Helder Coelho},
  journal = {Journal of Artificial Societies and Social Simulation},
  volume = {7},
  number = {3},
  title = {The Structure and Logic of Interdisciplinary Research in Agent-Based Social Simulation},
  year = {2004}
}

> This article reports an exploratory survey of the structure of interdisciplinary research in Agent-Based Social Simulation. One hundred and ninety six researchers participated in the survey completing an on-line questionnaire. The questionnaire had three distinct sections, a classification of research domains, a classification of models, and an inquiry into software requirements for designing simulation platforms. The survey results allowed us to disambiguate the variety of scientific goals and modus operandi of researchers with a reasonable level of detail, and to identify a classification of agent-based models used in simulation. In particular, in the interdisciplinary context of social-scientific modelling, agent-based computational modelling and computer engineering, we analyse the extent to which these paradigmatic models seem to be mutually instrumental in the field. We expect that our proposal may improve the viability of submitting, explaining and comparing agent-based simulations in articles, which is an important methodological requirement to consolidate the field. We also expect that it will motivate other proposals that could further validate, extend or change ours, in order to refine the classification with more types of models. 


---


# Paperless Philosophy as a Philosophical Method

@article{Bourget2010-BOUPPA,
  journal = {Social Epistemology},
  title = {Paperless Philosophy as a Philosophical Method},
  author = {David Bourget},
  number = {4},
  doi = {10.1080/02691728.2010.499180},
  pages = {363--375},
  publisher = {Taylor \& Francis},
  volume = {24},
  year = {2010}
}


> I discuss the prospects for new forms of professional communication in philosophy. I argue that online discussions and online surveys ought to play a more important role in communications between philosophers than they play today. However, there are major obstacles to the widespread adoption of these media as channels of communication between academics. I offer an overview of these obstacles and sketch a strategy for surmounting them. The strategy I propose involves the development of a new kind of service which could expand the reach of the analytic method in philosophy.

@bourget2010 looks at how digital methods can advance philosophy.

*Online Spaces*

Sub paper length arguments & refutations are currently lost thanks to the current publication mediums [p364] but a lack of prestege in blogs is limiting their use [p365]

> many verbally brief points which are potentially just as valuable as whole papers remain largely uncommunicated to the profession as a whole. [p364]

> I would not be surprised if it turned out that we spend significantly more time and energy on communication difficulties than philosophical problems per se when preparing articles [p364]

@bourget2010 also looks at online surveys and _philosophical registries_ that combine the two [p371]

> It is noteworthy that a registry of the kind sketched here could be particularly well suited to the application of a certain analytic methodology to philosophical problems. In some circles, it is widely believed that philosophical disputes are fuelled in large part by linguistic confusion—either the participants have a poor grasp of the meanings of the words they use, or they have a poor grasp of others’ meanings. On this view, the primary task of the philosopher is to dissipate the fog of language around the ideas under dispute. For most philosophical disputes, the closer we come to accomplishing this, the closer we will come to consensus. [p375]




### Could Arbitrary Imitation and Pattern Completion Have Bootstrapped Human Linguistic Communication?

@article{Tamariz2011-TAMCAI,
  title = {Could Arbitrary Imitation and Pattern Completion Have Bootstrapped Human Linguistic Communication?},
  doi = {10.1075/is.12.1.02tam},
  pages = {36--62},
  number = {1},
  volume = {12},
  journal = {Interaction Studies},
  year = {2011},
  author = {Monica Tamariz}
}

> The present study explores the idea that human linguistic communication co- opted a pre-existing population-wide behavioural system that was shared among social group members and whose structure reflected the structure of the environment. This system is hypothesized to have emerged from interactions among individuals who had evolved the capacity to imitate arbitrary, functionless behaviour. A series of agent-based computer simulations test the separate and joint effects of imitation, pattern completion behaviour, environment structure and level of social interaction on such a population-wide behavioural system. The results support the view that a system that could be co-opted for linguistic communication might arise in a population of agents equipped with arbitrary imitation for the purposes of pattern completion interacting in certain kinds of structured environments. Such pre-linguistic behavioural system could have bootstrapped communication and paved the way for biological capacities widely believed to be necessary for communication, such as shared intentionality and symbolicity, to evolve.

Uses agent based modelling to verify a linguist bootstrap thesis

> The objective of the present study was to explore the effect of a hypothesized capacity for function-independent or arbitrary imitation for pattern completion on the emergence of a behavioural system with the potential to bootstrap linguistic communication. (p30)

Compares itself to earlier simulations except that this drops many requirements

> Unlike most of those simulations, the present model does not involve shared goals, explicit symbolicity or intentional communication, and therefore it does not include mechanisms that help form conventional, shared mappings between objects and behaviours, such as the corrective feedback or knowledge transfer (p11)

Involves a description of the simulation model followed by a discussion of the results.

> The pivotal biological adaptation necessary for the emergence of coordinated, systematic mappings in a population is arbitrary imitation. (p31)




### Oppenheimer, P. E., & Zalta, E. N. (2011). A computationally-discovered simplification of the ontological argument. Australasian Journal of Philosophy, 89(2), 333-349.

bibtex: @article{oppenheimer2011computationally,
  title={A computationally-discovered simplification of the ontological argument},
  author={Oppenheimer, Paul E and Zalta, Edward N},
  journal={Australasian Journal of Philosophy},
  volume={89},
  number={2},
  pages={333--349},
  year={2011},
  publisher={Routledge}
}

> The authors investigate the ontological argument computation- ally. The premises and conclusion of the argument are repre- sented in the syntax understood by the automated reasoning engine prover9. Using the logic of definite descriptions, the authors developed a valid representation of the argument that required three non-logical premises. prover9, however, discovered a simpler valid argument for God’s existence from a single non-logical premise. Reducing the argument to one non-logical premise brings the investigation of the soundness of the argument into better focus. Also, the simpler representation of the argument brings out clearly how the ontological argument constitutes an early example of a ‘diagonal ar- gument’ and, moreover, one used to establish a positive conclusion rather than a paradox.

> Recently, however, we decided to investigate that 1991 analysis com- putationally, and represented the 1991 formulation of the argument in the automated reasoning system prover9. (p2)

Computational Implementation

> In what follows, we use typewriter font to indicate formulas that are in prover9 syntax. Our intention was to follow, as closely as possible, the structure of the argument in our 1991 paper, as outlined immediately above, when representing the premises and conclusion in prover9 syntax. (p7)

They faced the challenge of translating logical representation into computer code.

Code logic was external to the paper, although they appear to require a description of the code in the paper http://mally.stanford.edu/cm/ontological-argument/ , http://mally.stanford.edu/cm/ontological-argument/ontological.in

The code clearly needs justification as the epistemic endeavour was to demonstrate that the algorithmic implementation was a high fidelity translation of Ansel's argument.

> We will not here reproduce the proof that prover9 discovered, since proofs in clausal normal form are somewhat difficult to read. We make it available as an output file.  (p15)

> First, we think this analysis shows the value of employing computational techniques in the study of metaphysics. (p16)

Beauty & Pursuation

>  Indeed, if the reader were to analyze which clauses of each premise are used in the prover9 proof, then it would become clear exactly what part of the content of each of the logical and non-logical premises is actually used in the argument.  ... In any case, the computationally-simplified version of the argument reveals that it has a subtle logical beauty. (p17)

Compuational approach leads to a new insight

> Fifth, the new analysis of the argument brings out much more clearly that it deploys diagonal reasoning for a positive conclusion. By contrast, most diagonal arguments in the history of philosophy have been deployed to develop paradoxes (p18)


### A computer simulation of the argument from disagreement

@article{Gustafsson2012-PETACS,
  number = {3},
  journal = {Synthese},
  title = {A Computer Simulation of the Argument From Disagreement},
  author = {Johan E. Gustafsson and Martin Peterson},
  volume = {184},
  year = {2012},
  pages = {387--405},
  doi = {10.2307/41411200}
}

> In this paper we shed new light on the Argument from Disagreement by putting it to test in a computer simulation. According to this argument widespread and persistent disagreement on ethical issues indicates that our moral opinions are not influenced by any moral facts, either because no such facts exist or because they are epistemically inaccessible or inefficacious for some other reason. Our simulation shows that if our moral opinions were influenced at least a little bit by moral facts, we would quickly have reached consensus, even if our moral opinions were affected by factors such as false authorities, external political shifts, and random processes. Therefore, since no such consensus has been reached, the simulation gives us increased reason to take seriously the Argument from Disagreement. Our conclusion is however not conclusive; the simulation also indicates what assumptions one has to make in order to reject the Argument from Disagreement. The simulation algorithm we use builds on the work of Hegselmann and Krause (J Artif Soc Social Simul 5(3); 2002, J Artif Soc Social Simul 9(3), 2006).

Uses simulation to refute criticism of the Argument from Disagreement under certain conditions.

Importantly, it models a moral theory to show under what conditions it holds, then relates those conditions to the real world.


They cite Mackie (1977) & Shafer-Landau(2003) and Tersman(2006,p.xii). as examples of epistemic weakness in traditional arguments ...

> The first is exemplified in Mackie’s treatment: He offers no or little support for the claim that variations in moral opinions are more readily explained by the non-realist hypothesis than its realist rival. (388)

> So how can claims about disagreement disprove the existence or epistemic inefficacy of moral facts, given that we agree on many—or even most—moral issues?

The model is described in the paper but no source code is provided or linked.

> We shall model this by adopting a generalized version of a model originally developed by Hegselmann and Krause. (p390)

The simulation is used to generate data and then statistical analysis is performed.  The results are presented in tabular and graph form.




### Baumgaertner, Bert (2012). Vagueness Intuitions and the Mobility of Cognitive Sortals.   - _Minds and Machines_ 22 (3):213-234.

@article{Baumgaertner2012-BAUVIA,
  number = {3},
  journal = {Minds and Machines},
  author = {Bert Baumgaertner},
  pages = {213--234},
  title = {Vagueness Intuitions and the Mobility of Cognitive Sortals},
  volume = {22},
  year = {2012}
}

> One feature of vague predicates is that, as far as appearances go, they lack sharp application boundaries. I argue that we would not be able to locate boundaries even if vague predicates had sharp boundaries. I do so by developing an idealized cognitive model of a categorization faculty which has mobile and dynamic sortals (‘classes’, ‘concepts’ or ‘categories’) and formally prove that the degree of precision with which boundaries of such sortals can be located is inversely constrained by their flexibility. Given the literature, it is plausible that we are appropriately like the model. Hence, an inability to locate sharp boundaries is not necessarily because there are none; boundaries could be sharp and it is plausible that we would nevertheless be unable to locate them.

Constructs a conceptual model/algorithm to address vagueness in Sorites paradoxes.  Then attempts to prove this analytically.



### Blumson, Ben (2017). Anselm's God in Isabelle/HOL. _Archive of Formal Proofs_:9.

@article{Blumson2017-BLUAGI-2,
  title = {Anselm's God in Isabelle/HOL},
  year = {2017},
  author = {Ben Blumson},
  pages = {9},
  journal = {Archive of Formal Proofs}
}

> Paul Oppenheimer and Edward Zalta's formalisation of Anselm's ontological argument for the existence of God is automated by embedding a free logic for definite descriptions within Isabelle/HOL. 

Uses a computer proving language (Isabelle) to prove another computer generated argument.

The paper looks to be (in appearence) the closest philsophy has come to literate programming although the source code is elsewhere.


### Clarin in the Low Countries

bibtex: @incollection{Betti2017-BETPBC,
  editor = {J. Odijk and A. Van Hessen},
  title = {@PhilosTEI: Building Corpora for Philosophers},
  author = {Arianna Betti and Martin Reynaert and Hein Van Den Berg},
  pages = {379--392},
  year = {2017},
  booktitle = {Clarin in the Low Countries}
}


> For philosophers to be able to take a computational turn in their field, especially if that field relies heavily on historical material, it is crucial to be able to build high-quality, easily and freely accessible corpora in a sustainable format composed from multi-language, multi-script books from different historical periods. At the moment, corpora matching these needs are virtually non-existent. Within the CLARIN-NL project @PhilosTEI, we have addressed the problem of building this kind of corpora by developing an open-source, web-based, user- friendly workflow from textual images to TEI, based on state-of-the-art open-source OCR software Tesseract, and a multi-language version of TICCL, a powerful OCR post-correction tool. We have demonstrated the utility of the @PhilosTEI tool by applying it to a multilingual, multi-script corpus of important 18th to 20th century European philosophical texts.

Webbased OCR for gothic and roman type faces

> The main objective of the CLARIN-NL project @PhilosTEI was to develop a web-based, user- friendly workflow from scanned images of text to TEI (Text Encoding Initiative)  (p379)

> Computational tools and methods have significantly impacted philosophical research (van den Berg et al., 2014; Ess, 2004). Another ontology aiding philosophical research is given by (Grenon and Smith, 2009).

Challenges with copyright

> Importantly, many among these editions are not in open access, so their use within digital phi- losophy projects is severely limited. This applies to e.g. commercial electronic editions, and to the content provided by the TLG. (p381)



## David Lewis and the Kangaroo: Graphing Philosophical Progress

@incollection{Hellie2017-HELDLA-2,
  publisher = {Oxford: Blackwell},
  year = {2017},
  booktitle = {Philosophy's Future: The Problem of Philosophical Progress},
  author = {Benj Hellie},
  title = {David Lewis and the Kangaroo: Graphing Philosophical Progress},
  editor = {Russell Blackford and Damien Broderick}
}

> Data-driven historiography of philosophy looks to objective modeling tools for illumination of the propagation of influence. While the system of David Lewis (1941–2001), the most influential philosopher of our time, raises historiographic puzzles to stymie conventional analytic methods, it proves amenable to data-driven analysis. A striking result is that Lewis only becomes the metaphysician of current legend following the midpoint of his career: his initial project is to frame a descriptive science of mind and meaning; the transition to metaphysics is a rhetorically breathtaking escape from this program’s (inevitable) collapse. Understanding this process both aids a more focused debate whether it counts as progress, and also presents novel affordances for partisans on both sides to learn from Lewis’s right and wrong steps.

Benj employs a data-driven, impartial, model-building approach to history of philosophy. (p2)

Progress ...

> If there is progress in philosophy, it comes about through progression in philosophy: through development and change over time in what philosophers write. (p1)

Method ...

> My approach has been to construct force-directed graphs of Lewis’s autocitations: citations of his own work (nodes are publications, edges joining them represent mutual relevance, the spatial arrangement works out on its own when nodes try to get away from each other but are constrained by edges). (p3)

> My database of Lewis’s autocitations (compiled by hand) covers 129 works published by 2014, each of them assigned a date.3 Of these, 99 systemic works either cite or are cited by one another: there are 270 episodes of autocitation in all. With the assistance of David Balcarras, I have constructed force-directed visualizations of network graphs extracted from the data (Hellie 2016).

> These are of two kinds: graphs of development and of subject-matter. Development graphs depict the raw data of what cites what, and when. So edges are “directed”: there is a meaningful difference between the “source” of an edge and its “target”—namely, the source is the citing work, the target the cited work.



### Ashton, Zoe & Mizrahi, Moti (2018). Show Me the Argument: Empirically Testing the Armchair Philosophy Picture. _Metaphilosophy_ 49 (1-2):58-70.

@article{Ashton2018-MIZSMT,
  author = {Zoe Ashton and Moti Mizrahi},
  pages = {58--70},
  journal = {Metaphilosophy},
  number = {1-2},
  year = {2018},
  volume = {49},
  title = {Show Me the Argument: Empirically Testing the Armchair Philosophy Picture}
}

> Many philosophers subscribe to the view that philosophy is a priori and in the business of discovering necessary truths from the armchair. This paper sets out to empirically test this picture. If this were the case, we would expect to see this reflected in philosophical practice. In particular, we would expect philosophers to advance mostly deductive, rather than inductive, arguments. The paper shows that the percentage of philosophy articles advancing deductive arguments is higher than those advancing inductive arguments, which is what we would expect from the vantage point of the armchair philosophy picture. The results also show, however, that the percentages of articles advancing deductive arguments and those advancing inductive arguments are converging over time and that the difference between inductive and deductive ratios is declining over time. This trend suggests that deductive arguments are gradually losing their status as the dominant form of argumentation in philosophy.

An empiric test of whether philosophy is 'a priori armchair conceptual analysis'.  A computer assisted research to parse a corpus of philosophical texts.

"In order to get an idea of how many philosophy articles employ deductive and inductive arguments, we searched the JSTOR database using the deductive and inductive indicator words outlined in table 2." (p62)

> To sum up, our key findings are the following: (p67)
>
>  1. The ratio, and likewise percentage, of philosophy articles advanc- ing deductive arguments is higher than the percentage of articles advancing inductive arguments.
>  2. The ratios and percentages of philosophy articles advancing deductive arguments and those advancing inductive arguments are converging over time.
>  3. The difference between inductive and deductive ratios, and their percentages, is declining over time.

"This trend suggests that deductive arguments are gradually losing their status as the dominant form of argumentation in philosophy." (p68)



### Ashton, Zoe & Mizrahi, Moti (2018). Intuition Talk is Not Methodologically Cheap: Empirically Testing the “Received Wisdom” About Armchair Philosophy. _Erkenntnis_ 83 (3):595-612.

@article{Ashton2018-ASHITI,
  number = {3},
  pages = {595--612},
  author = {Zoe Ashton and Moti Mizrahi},
  journal = {Erkenntnis},
  volume = {83},
  title = {Intuition Talk is Not Methodologically Cheap: Empirically Testing the \textquotedblleftReceived Wisdom\textquotedblright About Armchair Philosophy},
  year = {2018}
}

> The “received wisdom” in contemporary analytic philosophy is that intuition talk is a fairly recent phenomenon, dating back to the 1960s. In this paper, we set out to test two interpretations of this “received wisdom.” The first is that intuition talk is just talk, without any methodological significance. The second is that intuition talk is methodologically significant; it shows that analytic philosophers appeal to intuition. We present empirical and contextual evidence, systematically mined from the JSTOR corpus and HathiTrust’s Digital Library, which provide some empirical support for the second rather than the first hypothesis. Our data also suggest that appealing to intuition is a much older philosophical methodology than the “received wisdom” alleges. We then discuss the implications of our findings for the contemporary debate over philosophical methodology. 

Computer assisted empiric study of use of inuition in philosophical work.  Parsed a corpus of philosophical texts to extract key words (JSTOR’s Data for Research (dfr.jstor.org) and HathiTrust’s Digital Library (hathitrust.org))

"In this paper, we follow in Andow’s (2015a) footsteps methodologically, but we seek to advance the contemporary debate over philosophical methodology by focusing on the role that intuitions play in philosophical argumentation." (p597)

"We also used these two databases to search for phrases, such as ‘seems that’, ‘appears that’, and ‘it seems to me that’, which are phrases that are indicative of appeals to intuition, through philosophy publications in English." (p598)

> In this paper, through a systematic survey of the JSTOR and HathiTrust databases, we have found that: (p610)
>
> 1. Intuition talk (where indicators of intuition talk include ‘intuit’, ‘intuition, ‘intuitions’, ‘intuitive’, and ‘intuitively’) in philosophy is not as recent as the ‘‘received wisdom’’ alleges (circa 1960s); it goes as far back as the 1800s;
> 2. Nineteenth and twentieth century philosophers appealed to intuition (where indicators of appeals to intuition include ‘it seems that’, ‘it appears that’, and ‘it seems to me that’) in argumentative contexts;
> 3. The proportion of publications in which philosophers appeal to intuition (as indicated by ‘it seems that’, ‘it appears that’, and ‘it seems to me that’) shows that the practice was accepted and fairly common, even early in the 1800s;
> 4. There is a positive correlation between intuition talk (as indicated by ‘intuit’, ‘intuition, ‘intuitions’, ‘intuitive’, and ‘intuitively’) and appeals to intuition (as indicated by ‘it seems that’, ‘it appears that’, and ‘it seems to me that’).


### Baek, Jongmin Jerome (2018). How to Solve Moral Conundrums with Computability Theory. _arXiv_.

@incollection{Baek2018-BAEHTS,
  year = {2018},
  booktitle = {arXiv},
  title = {How to Solve Moral Conundrums with Computability Theory},
  editor = {},
  pages = {N/A},
  author = {Jongmin Jerome Baek}
}
  
> Various moral conundrums plague population ethics: The Non-Identity Problem, The Pro- creation Asymmetry, The Repugnant Conclusion, and more. I argue that the aforementioned moral conundrums have a structure neatly accounted for, and solved by, some ideas in com- putability theory. I introduce a mathematical model based on computability theory and show how previous arguments pertaining to these conundrums fit into the model. This paper pro- ceeds as follows. First, I do a very brief survey of the history of computability theory in moral philosophy. Second, I follow various papers, and show how their arguments fit into, or don’t fit into, our model. Third, I discuss the implications of our model to the question why the human race should or should not continue to exist. Finally, I show that our model ineluctably leads us to a Confucian moral principle.

Attempts to model moral philosophy on computability theory and the Turing-Church Thesis.  Uses analytic proof rather than computation.



### Pence, C. H., & Ramsey, G. (2018). How to do digital philosophy of science. Philosophy of Science, 85(5), 930-941.

bibtex: @article{pence2018digital,
  title={How to do digital philosophy of science},
  author={Pence, Charles H and Ramsey, Grant},
  journal={Philosophy of Science},
  volume={85},
  number={5},
  pages={930--941},
  year={2018},
  publisher={University of Chicago Press Chicago, IL}
}

> Our understanding of science is being broadened by the digitization and automated analysis of the various outputs of the scientific process, such as scientific literature, archival data, and networks of collaboration and correspondence (p1)

> digital philosophy of science lets us ask a new class of questions (p1)

Looks at close reading vs distant reading ...

> With distant reading, we input a large body of literature into a computer, and use it to do the “reading” for us, extracting large-scale patterns that would be invisible or impractical to find otherwise (p2)

>  With close reading, a philosopher will have an impressive command over a limited domain (p3)

> Because digital philosophy of science is a relatively new field, not only is there no set of standard tools, (p4)

Advantages ...

> One of the most significant advantages of distant reading comes from the ability to engage with corpora significantly larger than those usually treated by philosophers and historians of science (p4)

> Another advantage comes from the ability of analytical algorithms to parse texts in ways that even well trained close readers cannot (p4)

Tools available (2018) (p6)

  - google n-grams
  - JSTOR’s Data for Research project 
  - Indiana Philosophy Ontology project
  - Omeka is a free, open-source software product that allows users to construct online archives and museum exhibitions,
  - network analysis tools available is Gephi
  - If the data to be analyzed is text, a popular choice is Voyant Tools
  - RLetters (Pence 2016), available at <http://www.rletters.net> book level full text search
  - R lang & knittr
  - figshare
  - zenodo

Challenges (p11)

  - copyright
  - data management 
  - Reproducibility

> Philosophers are not, as a rule, accustomed to producing large amounts of data as part of our research. (p12)

Reproduceability has 3 issues ...

> software must be reproducible—that is, easily installed and run by those with the relevant technical expertise (p13)

> corpora must be reproducible ... difficult challenge, particularly if one has negotiated access to a body of copyrighted materials for analysis.

> original forms of data must be—and remain—available.


> A recurring problem with digital humanities results consists in how we can be certain that we have obtained genuine information supporting the conclusions we hope to draw. (p13) 

> We can in part resolve this by proceeding in an “hypothesis-first” manner— forming clear hypotheses prior to performing analyses (p14)

> Many analyses in the digital humanities lack statistical validation, and have only a history of successful use as evidence in their favor (see, e.g., the discussion of validation in Koppel, Schler, and Argamon 2009). (p14)

> Pence has recently combined existing work on an episode in the history of biology (Pence 2011) with digital tools (Ramsey and Pence 2016), to produce a more general hypothesis about debates over paradigm change, which is now ripe for a non-digital analysis (Pence in preparation). (p15)


### What Isn't Obvious About Obvious: A Data-Driven Approach to Philosophy of Logic

@incollection{Mizrahi2019-MIZWIO,
  editor = {Andrew Aberdein and Matthew Inglis},
  title = {What Isn't Obvious About Obvious: A Data-Driven Approach to Philosophy of Logic},
  author = {Moti Mizrahi},
  pages = {201--224},
  year = {2019},
  publisher = {London: Bloomsbury Press},
  booktitle = {Advances in Experimental Philosophy of Logic and Mathematics}
}

> It is often said that ‘every logical truth is obvious’ (Quine 1970: 82), that the ‘axioms and rules of logic are true in an obvious way’ (Murawski 2014: 87), or that ‘logic is a theory of the obvious’ (Sher 1999: 207). In this chapter, I set out to test empirically how the idea that logic is obvious is reflected in the scholarly work of logicians and philosophers of logic. My approach is data-driven. That is to say, I propose that systematically searching for patternsof usage in databases of scholarly works, such as JSTOR, can provide new insights into the ways in which the idea that logic is obvious is reflected in logical and philosophical practice, i.e., in the arguments that logicians and philosophers of logic actually make in their published work.

Uses methods of data science to analyse a large corpus of logical and philosophical texts in order to shed light on logical, philosophical, and metaphilosophical questions.

"Data Driven" text analysis only.

Methods ....

> I propose to use indicator words to test how the idea that ‘logic is a theory of the obvious’ (Sher 1999: 207) and that ‘logic is [...] necessary and a priori’ (Russell 2015: 793) is reflected in the scholarly work of logicians and philosophers of logic. (p6)

> The data driving this empirical study is taken from JSTOR Data for Research (jstor.org/dfr) (p8)

> To make sure that the aforementioned indicator words occur in the contexts of arguments, to rule out non- argumentative (e.g., rhetorical) instances of ‘obvious’ as much as possible, and to test predictions (A)-(C) above, I have anchored them to the argument indicators ‘therefore’ and ‘follows’ within 10 words of each other (p8)

Statistical analysis was then performed on the data


