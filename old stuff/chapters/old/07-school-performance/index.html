<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Dave Kinkead">
  <title>What can student results tell us about school performance?</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="assets/styles.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">What can student results tell us about school performance?</h1>
<p class="author">Dave Kinkead</p>
</header>
<h2 id="introduction">Introduction</h2>
<p>Let's begin with a simple claim, one that I hope is incontrovertible -- that schooling somehow affects student results. However we measure the academic achievement of students - whether by <em>declarative knowledge</em>, the learning and appropriate recall of particular facts; or by <em>procedural knowledge</em>, the application of skill and know-how -- few people, if any, would claim that school policies, pedagogy, and environment have <em>no</em> causal impact on students.</p>
<p>So it follows that measuring school performance is important. Parents want to know which school will best educate their children; principals want to know if their leadership makes a difference; politicians and bureaucrats want to know if their policies work and public resources are invested appropriately. As a society we invest significant amounts of time and money in various endeavours like the National Assessment Program - Literacy and Numeracy (NAPLAN), Trends in International Mathematics and Science Study (TIMSS), and the Programme for International Student Assessment (PISA), trying to measure exactly this.</p>
<p>To do this, we use a range of metrics: Standardised literacy and numeracy tests like NAPLAN; the Peabody Picture Vocabulary Test <span class="citation" data-cites="dunn1965">(L. M. Dunn et al. 1965)</span>; IQ scores or the Wechsler Intelligence Scale for Children (WISC-IV) <span class="citation" data-cites="wechsler2003">(Wechsler 2003)</span>. None of these assessments however, measure school performance directly. Instead, they rely on a proxy measure - student results - to <em>infer</em> school performance. Thus, when student results improve, we can <em>infer</em> that some aspect of schooling <em>caused</em> this; that <em>school performance</em> has improved.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>Perhaps.</p>
<p>Accurately measuring school performance this way is hard. The challenges associated with inferring school performance from student results have long been documented <span class="citation" data-cites="coleman1970">(Coleman and Karweit 1970)</span>. Ecological models, for example, stress the important role non-school factors like family and neighbourhood have on student performance <span class="citation" data-cites="bronfenbrenner1994">(Bronfenbrenner 1994, <span class="citation" data-cites="zubrick2000">Zubrick et al. (2000)</span>)</span>. Further clouding our understanding are the often competing causal theories that attempt to explain how schools affect student achievement - peer effect <span class="citation" data-cites="hanushek2003">(Hanushek et al. 2003)</span>, class size policies <span class="citation" data-cites="ehrenberg2001">(Ehrenberg et al. 2001)</span>, or teacher training and qualifications <span class="citation" data-cites="kosgei2013">(Kosgei et al. 2013)</span>. How, and to what degree, schools themselves impact student achievement remains an open question. How much the changes in student results can be attributed to school performance is, therefore, also uncertain.</p>
<p>With the aid of computer simulation, I develop a simple model of school performance in order to assess how warranted the inference mechanism <em>from student results to school performance</em> really is. All possible confounders are abstracted away creating an 'ideal world' for assessing the quality of this inference mechanism. I then demonstrate how a number of common education scenarios leads to a complete failure of the student results to school performance inference mechanism. My argument is simple - if an inference is unreliable in an ideal setting, then it is certainly unreliable in a non-ideal setting. Thus, if the conditions in this model are present in the real world, then we should be very sceptical inferring anything about school performance from student results.</p>
<h2 id="motivation-methodology">Motivation &amp; Methodology</h2>
<p>Accurately measuring school performance is hard. The limits of causal knowledge are well known in science and philosophy. Causation cannot be observed directly - it can't be seen, heard, or touched. Neither can it be known <em>a priori</em>. Causal claims might be true or false, but they are never contradictory <span class="citation" data-cites="hume1748">(Hume 1748 ยง4.2.16)</span>. Instead, causal connections must be <em>inferred</em> from their observable, posited effects. In order to discover the causes of effects, we try to hold all but a few variables fixed, and observe the covariance between them in order to identify causality.</p>
<p>In complex systems accurate causal inferences are especially challenging. Common causes, feedback loops, under-determination, over-determination, and causal indeterminacy all strain the certainty of our inference mechanisms despite the best controls, protocols, and experimental design we might put in place. Causal inference is difficult. Inferring the causal impact of schools on students in a complex education system with multiple confounders is especially difficult.</p>
<p>So just how warranted is this inference from student results to school performance? In some scenarios, inferring school performance from student results might be perfectly justified. Changes in student results might be largely or even wholly explainable by a school's causal impact. In many other scenarios however, we might have serious grounds for scepticism. Confounders such as parental age and socio-economic status <span class="citation" data-cites="caro2009">(Caro, McDonald, and Willms 2009)</span>, birth weight, neighborhood characteristics <span class="citation" data-cites="nghiem2015">(Nghiem et al. 2015)</span>, or even a student's breakfast consumption <span class="citation" data-cites="adolphus2013">(Adolphus, Lawton, and Dye 2013)</span> might explain a great deal about differences in student results.</p>
<p>If inferring from observable effects to their causes is difficult, then judging the quality of the inference mechanism is even harder. Doing so requires some standard against which we can make comparisons but our knowledge of this standard is limited by the same problem of inference. How can we judge the quality of the inference from student results to school performance if we can't be certain what is the cause of student results in the first place? We lack the epistemological foundations to properly ground our second order judgements.</p>
<p>Computer simulation however, offers us one way out of this problem. Simulation allows us to not only model how we think the world <em>is</em>, but to also stipulate how we think the world <em>should be</em>. It allows us to know the causal relationships <em>within</em> the model with certainty because they are explicitly stipulated in code <em>ex ante</em>. With causality known, we can then observe the empiric data the simulation generates and assess the quality of the inference mechanism. We can judge how good the inference mechanism from student results to school performance really is - in our model at least.</p>
<p>The purpose of this simulation is not to explain or predict the real world but to create a yard stick by which we can judge our causal inferences in the real world. The model simplifies and abstracts away all possible confounding causes of student performance. Importantly, it eliminates any errors when measuring student performance and stipulates that schooling is the <em>only</em> cause of changes in student performance.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> This creates ideal conditions for assessing the quality of our second order judgements.</p>
<p>Because the causal impact of a school on student achievement is known by stipulation, we can assess how accurately empiric data about student results maps to the stipulated causal impact of the school - to our belief about school performance. If the inference mechanism from student result to school performance is warranted in the simulation when the causal mechanism is stipulated, then we have some grounds to be confident about the inference mechanism in the real world, additional confounders not withstanding. <em>But if the inference isn't warranted when the causal mechanism is known, then it can't be warranted when the causal mechanism is unknown.</em> This simulation will therefore allow us to say when the student result to school performance inference <em>might</em> be warranted, and when it <em>cannot be</em> warranted.</p>
<p>Written in <a href="http://Coffeescript.org/">Literate Coffeescript</a>, this article is simultaneously a philosophical argument and a computer simulation that demonstrates the claims of the argument. Literate Programming <span class="citation" data-cites="knuth1984">(Knuth 1984)</span> involves embedding computer code within a written argument and has much to offer scholarly writing. Firstly, it ensures that all assumptions of the model are explicit. Computer programs are deterministic, so all the instructions necessary for the simulation to run have to be explicitly documented. Literate Programming also allays concerns relating to validation and replication. Often, simulations are 'black boxes' of code - opaque to the reader and reviewer alike. Because all the code necessary for the running simulation is embedded in the article, replication is as simple as following the installation instructions in the appendix.</p>
<p>I make no assumptions about the reader's knowledge of computer programming. Code is indicated by <code>monospace font and indented blocks</code>, is written to be as informative as possible, and is fully described in the surrounding text. Any code that is not germane to the argument itself has been placed in the appendix. Coffeescript is used because it runs in any modern web browser and has a syntax close to natural language. Best viewed in HTML at <a href="http://blind-review.github.io/school-performance/" class="uri">http://blind-review.github.io/school-performance/</a> to take advantage of the interactive visualisations, a static but less engaging version of this article is available in PDF or print.</p>
<h2 id="a-model-of-school-performance">A Model of School Performance</h2>
<p>We begin by modelling students. Students have a level of academic achievement measured from a minimum of <code>0.0</code> to a maximum of <code>1.0</code>. Academic achievement is broadly construed and can be interpreted as any attribute of value that can be influenced by schooling. This achievement is uniformly randomly generated and is centred around a stipulated mean of <code>0.5</code>.</p>
<pre><code>class Student
  constructor: () -&gt;
    @achievement = Math.random()</code></pre>
<p>Next we model schools. Schools are collections of students upon whose acheivement they causally impact. In short, schools teach students. The causal impact of a school on a student's academic performance ranges from <code>-1.0</code> (strong negative impact) to <code>1.0</code> (strong positive impact). This impact is the same for all students and is fixed for the duration of the simulation. Again, no claim is made about how educational impact is transmitted to student achievement in the real world. Policy, pedagogy, or the school environment are all possible causal mechanisms compatible with this model. The key stipulation is that <code>impact</code> is the <em>only</em> causal mechanism at work.</p>
<pre><code>class School
  constructor: (@id, @impact) -&gt;</code></pre>
<p>Finally, we create a class to encapsulate the simulation itself. We construct the simulation with a profile containing information about schools and student distribution. We then create 1000 students of random achievement and assign them in the schools according to the simulation profile.</p>
<pre><code>class Simulation
  constructor: (@profile) -&gt;
    @schools = for school, id in @profile.schools
      new School(id, school.impact)
    @students = [1..1000].map () =&gt;
      student = new Student()
      student.school = assign student, @schools, @profile.skew
      student</code></pre>
<p>The initial assignment of students between schools is determined by a skew factor ranging from <code>0.0</code> (all students of below average achievement are in the first school) to <code>1.0</code> (all students of above average achievement students are in the first school). The default value of <code>0.5</code> results in an even distribution of students by achievement. Subsequent enrolments will be random.</p>
<pre><code>  assign = (student, schools, skew=0.5) -&gt;
    [first, second] = if student.achievement &gt; 0.5 then [0,1] else [1,0]
    if Math.random() &lt; skew then schools[first] else schools[second]</code></pre>
<p>Events in the simulation will occur during a generic time period called a <code>tick</code>. A tick can represent any fixed period of time such as a term, semester, or year. During each tick schools will <code>teach</code> students, some students will <code>graduate</code>, and some new students will <code>enrol</code>.</p>
<pre><code>Simulation::tick = () -&gt;
  @teach()
  @graduate()
  @enrol()</code></pre>
<p>Schools causally impact students' achievement. Schools teach and students learn. Again, the actual causal mechanism the model describes could be a variety of influences such as pedagogy, policy, or classroom environment.</p>
<pre><code>Simulation::teach = () -&gt;
   @students.forEach (student) -&gt;
     student.learn()</code></pre>
<p>As a non-ecological model however, schooling is the <em>only</em> mechanism by which student achievement can change within the model. The causal impact on student achievement is assumed to be linear and a constraint is applied to ensure achievement remains between <code>0.0</code> and <code>1.0</code>.</p>
<pre><code>Student::learn = (transference=0.2) -&gt;
  @achievement = @achievement * (@school.impact * transference + 1)
  @achievement = Math.min @achievement, 1.0</code></pre>
<p>During each tick, a percentage of students will graduate and be replaced by new students enrolling.</p>
<pre><code>Simulation::graduate = (graduation_rate=0.2) -&gt;
  @graduates = @students.filter (student) -&gt;
    Math.random() &lt; graduation_rate</code></pre>
<p>Depending on the <em>selectivity</em> parameter, some students will attempt to enrol in the perceived best performing school. If more than half of the total students are attempting to enrol in one particular school, the school will select the highest achieving students first so that all schools have roughly even numbers of students.</p>
<pre><code>Simulation::enrol = () -&gt;
  [best, worst] = @rank_schools()

  @graduates.forEach (student) =&gt;
    student.achievement = Math.random()
    if Math.random() &lt; @profile.selectivity
      student.school = if student.achievement &gt; 0.5 
      then @schools[best.id] 
      else @schools[worst.id]        </code></pre>
<p>Identifying the 'best' school requires us to rank schools based on student performance so we create a simple league table that all students have knowledge of.</p>
<pre><code>Simulation::rank_schools = () -&gt;
  @measure_schools()
  [best, worst] = if @schools[0].score &gt; @schools[1].score
  then [@schools[0], @schools[1]]
  else [@schools[1], @schools[0]]</code></pre>
<p>Measuring school performance is then done by calculating the average student achievement in each school. This acts as an error free method of student assessment which removes concerns about measurement validation from the model. School performance will therefore perfectly track the academic achievement of the students enrolled.</p>
<pre><code>Simulation::measure_schools = () -&gt;
  @schools.map (school) =&gt;
    students = @students.filter (student) -&gt;
      student.school.id is school.id
    total = students.map (student) -&gt;
        student.achievement
      .reduce (prev, curr) -&gt;
        prev + curr
    school.score = total / students.length</code></pre>
<p>We now have a complete model of students with initial uniformly random <code>achievement</code>; schools whose stipulated <code>impact</code> is the only mechanism for affecting student achievement; a perfect measure of school performance as average student achievement; methods for some student to graduate and new ones to enrol; and a means of varying how much <em>selectivity</em> is present in the school system as well as the initial <em>skew</em> of above average students. In short, we have created <em>perfect conditions</em> for measuring school performance.</p>
<h2 id="simulations">Simulations</h2>
<p>With the model defined, we begin with a test to ensure the simulation is working as expected. We will begin with students split evenly between the two schools. We stipulate that schools have no causal impact on student achievement, and that there is no selectivity within the system - i.e. all students will enrol randomly. Student achievement is represented in colour - blue for &gt; 0.5 and red for &lt; 0.5 achievement.</p>
<p>What we <em>should</em> observe is no significant change within and between schools. Random enrolment and student achievement fully explain school performance. The profile of the simulation is expressed in the code below and the simulation can be started or stopped by clicking on it. The movement in the simulation visually represents a <code>tick</code>.</p>
<pre><code>sanity_check_1 = { 
  schools: [{impact: 0.0}, {impact: 0.0}],
  selectivity: 0.0
}</code></pre>
<figure class="simulation">
<div id="sanity-check-1">

</div>
<figcaption>
Simulation 1: No impact, no selectivity.
</figcaption>
</figure>
<p>Running the simulation generates the expected results. During each tick, the <code>teach</code> method has no impact on student achievement because both schools have <code>0.0</code> impact. Some students graduate and are replaced with new students of random achievement. As such, school performance, measured by average student achievement, remains close to 0.5.</p>
<p>Next, we will model two schools with different causal impact - one positive and one negative - but again with no selectivity. While both schools will start with similar student achievement levels, the <code>teach</code> method <em>should</em> see student achievement in the first school increase while it decreases in the second.</p>
<pre><code>sanity_check_2 = { 
  schools: [{impact: 0.5}, {impact: -0.5}],
  selectivity: 0.0
}</code></pre>
<figure class="simulation">
<div id="sanity-check-2">

</div>
<figcaption>
Simulation 2: School impact, no selectivity.
</figcaption>
</figure>
<p>Again, the simulation generates the expected results with one school's performance stabilising at approximately <code>0.66</code> and the other at <code>0.33</code>. In both cases, the simulation performed as expected and our inference from student results to school performance is warranted. In these scenarios we can reliably infer school performance from student results.</p>
<h2 id="school-performance-as-shifting-averages">School Performance as Shifting Averages</h2>
<p>Most schools systems have some degree of selectivity. This might be selectivity on the part of the school where only the top achieving students are admitted; or it might be selectivity on the part of the students or parents who explicity choose one school over another. Selectivity can also be implicit when for example, parents choose a 'good' neighbourhood with 'good' schools to live in.</p>
<p>In the next scenario, we take parameters from Simulation 1 where schools have no causal impact on student achievement, but introduce selectivity into the model. Because both schools are identical in terms of their causal impact, and school <code>impact</code> is the only causal mechanism in the model, <em>any changes in school performance must be the result of selectivity</em>.</p>
<pre><code>shifting_averages = { 
  schools: [{impact: 0.0}, {impact: 0.0}],
  selectivity: 0.5
}</code></pre>
<figure class="simulation">
<div id="shifting-averages">

</div>
<figcaption>
Simulation 3: No impact but with selectivity.
</figcaption>
</figure>
<p>While the performance of both schools is approximately <code>0.5</code> when the simulation begins, any minor imbalance in relative performance caused by random variation in new student achievement results in a run-away effect. As soon as one school is perceived to perform better than others, <em>selectivity</em> ensures that students who do selectively enrol, choose the school with the higher percentage of high achievement students. After a few ticks, the simulation stabilises with one school performing at approximate <code>0.63</code> and the other at <code>0.37</code>.</p>
<p>Recall however that the impact of schools is stipulated as zero - both schools are identical. Individual student achievement never changes because schools have no impact in this scenario. The large differences in school performance are therefore completely explained by <em>selectivity</em>. As selectivity and the percentage of students enrolling non-randomly increases, so too does the performance difference. Differences in school performance as measured by student achievement are the result of nothing more than shifting averages of student achievement. When selectivity is present, the inference from student results to school performance is unreliable.</p>
<h2 id="performance-is-relative">Performance is Relative</h2>
<p>The previous simulation showed how significant performance differences can arise even when schools are causally identical. The next simulations demonstrate how a school with a low or negative impact can appear to perform well above what it should. We begin with two schools having differing levels of negative impact but with no selectivity. In this case the average performance of both schools <em>should</em> decrease, propped up only by new enrolments whose average achievement is <code>0.5</code>.</p>
<pre><code>relative_1 = { 
  schools: [{impact: -0.25}, {impact: -0.5}],
  selectivity: 0.0
}</code></pre>
<figure class="simulation">
<div id="relative-1">

</div>
<figcaption>
Simulation 4: Negative impact, no selectivity.
</figcaption>
</figure>
<p>Again, the simulation results are as expected. Both schools performed poorly but the school with the lowest causal impact performed the worst. Next however, we introduce selectivity to the same schools and students.</p>
<pre><code>relative_2 = { 
  schools: [{impact: -0.25}, {impact: -0.5}],
  selectivity: 0.5
}</code></pre>
<figure class="simulation">
<div id="relative-2">

</div>
<figcaption>
Simulation 5: Negative impact with selectivity.
</figcaption>
</figure>
<p>When selectivity is present, the inference from student results and school performance breaks down again. The school with the negative but better causal impact performs far better than its causal impact says it should - increasing average student achievement from <code>0.4</code> in Simulation 4 to <code>0.5</code> in Simulation 5. Meanwhile, the school with the worst causal impact performs much worse than it should - decreasing average student achievement from <code>0.33</code> to <code>0.22</code>. The schools remained the same in both simulations. The only change in the simulations, and therefore only causal of the change, was the introduction of selectivity.</p>
<p>As selectivity increases, so too does the disconnect between perceived performance and causal impact. The mere presence of a school with lower causal impact on student achievement combined with selectivity results in the higher achievement students enrolling in the <em>least worst</em> school, thereby <em>inflating</em> that school's apparent performance. Thus, school performance as measured by student achievement is determined not only by the causal impact of a school but also by the relative performance of other schools. This is not to say that school performance <em>is</em> relative, but rather that the performance of one school is affected by the performance of another, whenever selectivity is present. Again, the inference from student results to school performance is unreliable.</p>
<h2 id="initial-conditions-matter">Initial Conditions Matter</h2>
<p>In an egalitarian utopia, every child would have the same opportunities as every other. The biological lottery wouldn't affect educational outcomes. Obviously, this is not our reality - initial conditions matter. Until now, we have looked at scenarios where both schools started with similar initial random distributions of students. In the next simulations, we add a new parameter, <code>skew</code>, that alters the initial enrolment of students.<br />We continue with the same 1000 students of random achievement (mean <code>0.5</code>) but set the initial distribution between schools. A <code>skew</code> value of <code>0.75</code> here means that 75% of the above average, and therefore only 25% of the below average students, will initially be enrolled in the first school. The default value of <code>0.5</code> means there is an equal distribution of achievement.</p>
<p>In the next simulation, we stipulate that schools have different causal impact but the initial distribution of student achievement is skewed in favour of the school with the lowest impact. No selectivity is present so we should expect the initial mismatch between school impact and performance to be corrected over time.</p>
<pre><code>head_start_1 = { 
  schools: [{impact: -0.25}, {impact: 0.25}],
  selectivity: 0.0,
  skew: 0.75
}</code></pre>
<figure class="simulation">
<div id="head-start-1">

</div>
<figcaption>
Simulation 6: Mixed impact with skew.
</figcaption>
</figure>
<p>As expected, any imbalance in the initial distribution when selectivity is absent is eliminated given enough time. In each tick, the causal impact of schools affects student achievement, and every enrolling cohort normalises school performance to a degree. The first school, while appearing to perform strongest initially, eventually performs poorly, with the opposite occurring in the second school.</p>
<p>Next, we add selectivity to the same parameters and see how this changes performance.</p>
<pre><code>head_start_2 = { 
  schools: [{impact: -0.25}, {impact: 0.25}],
  selectivity: 0.75,
  skew: 0.75
}</code></pre>
<figure class="simulation">
<div id="head-start-2">

</div>
<figcaption>
Simulation 7: Mixed impact with skew and selection.
</figcaption>
</figure>
<p>Again, when selectivity is present school performance no longer reflects a school's stipulated causal impact. A skewed initial distribution of students and selectivity results in a school with a much weaker causal impact performing better than a school with a much stronger causal impact. Given a sufficiently skewed initial distribution, schools with negative causal impact can continue to outperform schools with positive impact. Yet again, the presence of selectivity in the school system undermines the student results to school performance inference mechanism.</p>
<h2 id="discussion">Discussion</h2>
<p>Measuring school performance is important but we cannot measure it directly. Instead, we rely on student results as a proxy, and <em>infer</em> school performance. This of course, raises a number of epistemic challenges. Few people if any would claim that current school performance measurement regimes that rely on student results as proxy data such as NAPLAN are perfect. What these simulations demonstrate however, is that <em>if selectivity is present, then the inference from student results to school performance is unwarranted</em>. If a causal inference mechanism isn't warranted when causes are known with certainty, then it seems highly impausible that the inference can be warranted when causes aren't known or observable.</p>
<p>The inference from student results to school performance is poor even under the very best epistemic conditions. The model above allows us to stipulate the behaviour of much that is uncontrollable in the real world. Within the model, our knowledge of student achievement is perfect and not affected by test errors, strategic teaching, or exam stress. So too is our knowledge of the causal mechanism. As a non-ecological model, we have stipulated that the only what student achievement can change in the simulation is via school impact. We could not ask for more perfect conditions from which to <em>infer</em> causal impact yet even here the link between proxy evidence and actual cause breaks down. <em>We should therefore be very skeptical about inferring school performance from student results</em>.</p>
<p>This is of course, a purely theoretical argument. It remains an open empiric question just how well the simulation models reality, and how much selectivity occurs within our school systems. Social scientists are likely to be better placed answering this question than philosophers are, but a few observations about the Australian context are germane. Approximately 35% of all students currently attend a non-government school <span class="citation" data-cites="abs2014">(Statistics 2014)</span> indicating a minimum level of explicit selectivity. Then there is selectivity within government schools. Data on what percentage of students attend their <em>nearest</em> school is difficult to find, as is data on parents moving to different school catchment zones because of perceived school performance, but anecdotal evidence suggests this too occurs.</p>
<p>One might object to my conclusion by claiming that the model described doesn't accurately reflect the real world. This is certainly true but not grounds to reject the conclusion. All models are abstractions and simplifications of reality - that is their strength. In this case, the model described presents a best case epistemic scenario for measuring school performance. As such, the simplification of the model <em>strengthens</em> the claims for epistemic skepticism towards school performance.</p>
<p>Despite its simplicity, the model also appears to conform with empiric observation. In the sanity check simulations, the model performed exactly as expected. When selectivity was introduced, the simulation was compatible with recent Australian data. <span class="citation" data-cites="nghiem2015">Nghiem et al. (2015)</span> analysis of the Longitudinal Study of Australian Children showed that non-government (and therefore selectively enrolled) schools had higher average student NAPLAN results but once controlled, performed equally or worse in the case of Catholic schools.</p>
<p>Some might also simply dispute my claim that student results are typically used for measuring school performance. NAPLAN, Peabody, and Wechsler tests are intended for measuring student, not school performance. Longitudinal <span class="citation" data-cites="zubrick2000">(Zubrick et al. 2000)</span>, predictive <span class="citation" data-cites="lavin1965">(Lavin 1965)</span>, and psychological studies of academic performance <span class="citation" data-cites="pintrich1990">(Pintrich and De Groot 1990)</span> all rely on these measures without making claims about school performance. In short, they might argue that my conclusion may be entailed but that it is poorly targeted. While it is certainly true that student results are used for much more than assessing school performance, student results are still used to infer school performance by parents, teachers, and policy makers alike. NAPLAN is explicit on this - &quot;[s]chools can gain detailed information about how they are performing, and they can identify strengths and weaknesses which may warrant further attention.&quot; <span class="citation" data-cites="naplan2015">(NAPLAN 2015)</span></p>
<p>The impact of student intake and composition has long been acknowledged to play an important role in determining school performance <span class="citation" data-cites="thrupp1995">(Thrupp 1995, <span class="citation" data-cites="thrupp1999">Thrupp (1999)</span>, <span class="citation" data-cites="thrupp2006">Thrupp and Lupton (2006)</span>)</span>. What this simulation so graphically demonstrates is how these common scenarios further complicate research into school performance by undermining our inference mechanisms even in ideal settings. <em>We should be very skeptical about inferring school performance from student results</em>.</p>
<hr />
<h1 id="appendix">Appendix</h1>
<p>This article is written in Literate Coffeescript. Literate programming has a great deal to offer the humanities, not least of which is that it makes replication available to all readers.</p>
<p>To build the simulation from the raw paper, download the project from <a href="https://github.com/blind-review/school-performance">the repo</a> and type <code>make paper</code> in the command line. Make sure you've got <a href="http://Coffeescript.org/">Coffeescript</a> and <a href="http://pandoc.org">Pandoc</a> installed first.</p>
<p>Running a simulation with your own parameters is easy. You just need to specify the parameters and call <code>display(target-location, parameters)</code> and add a target location in HTML <code>id=&quot;target-location&quot;</code></p>
<h2 id="browser-code">Browser Code</h2>
<p>Much of the browser code required in this simulation is not germane to the argument and so has been extracted to the appendix. To make things look pretty, we will use the <a href="http://d3js.org/">D3.js library</a> by Mike Bostock. We will also set some global variables from the browser such as height and width.</p>
<pre><code>d3      = require &#39;d3&#39;
width   = window.innerWidth - 25 || 600
height  = width * 0.4</code></pre>
<p>We will be running multiple simulations in the browser so will need a way of creating different ones. Here we define a <code>display</code> method for creating a simulation and binding it to a canvas with click events. When a simulation canvas is clicked, the interval runner starts and calls the <code>tick</code> method every 1000 milliseconds.</p>
<pre><code>display = (id, params) =&gt;
  runner = false
  simulation = new Simulation params
  canvas = d3.select(&quot;##{id}&quot;)
    .append(&quot;svg:svg&quot;)
    .attr &quot;height&quot;, Math.max(width * 0.4, height * 0.8)
    .attr &quot;width&quot;, width
    .on &quot;click&quot;, () -&gt;
      if runner
        clearInterval runner
        runner = false
      else 
        runner = setInterval () -&gt;
          tick simulation
        , 1000
  canvas.append(&#39;text&#39;)
    .attr &quot;y&quot;, () -&gt; height * .7
    .attr &quot;x&quot;, () -&gt; width * .36</code></pre>
<p>In every tick cycle, we run call simulation's <code>teach</code> and <code>graduate</code> methods. We then <code>render</code> the simulation to calculate the x &amp; y coordinates for the students, and update the canvas.</p>
<pre><code>  tick = (simulation) -&gt;
    simulation.tick()
    render simulation
    draw canvas.selectAll &quot;circle&quot;        </code></pre>
<p>We then <code>draw</code> the students on the canvas. We will represent our students as coloured circles and schools by student proximity. We will also append the school averages in text form.</p>
<pre><code>  draw = (students) -&gt;
    students.transition()
      .duration 1000
      .style &quot;fill&quot;, (d) -&gt; colour d, &#39;achievement&#39;
      .style &quot;opacity&quot;, 0.5
      .attr &quot;r&quot;, 8
      .attr &quot;cx&quot;, (d) -&gt; d.x
      .attr &quot;cy&quot;, (d) -&gt; d.y
    canvas.select &quot;text&quot;
      .text &quot;#{simulation.schools[0].score.toFixed(5)} 
        - Average Student achievement 
        - #{simulation.schools[1].score.toFixed(5)}&quot; </code></pre>
<p>Finally, we setup the initial rendering.</p>
<pre><code>  setup = () -&gt;
    render simulation
    students = canvas.selectAll &quot;circle&quot;
      .data simulation.students
    students.enter()
      .append &quot;circle&quot;
      .style &quot;fill&quot;, (student) -&gt;
        colour student, &#39;achievement&#39;
      .style &quot;opacity&quot;, 0.5
      .attr &quot;r&quot;, 8
      .attr &quot;cx&quot;, (d) -&gt; d.x
      .attr &quot;cy&quot;, (d) -&gt; d.y 
                 
  setup()</code></pre>
<p>In the browser code above, we have relied on a few helper methods. The first of these represents student achievement graphically using colour. Blue represents high achievement and red low achievement. With a little bit of maths, we can convert achievement on a range of 0.0 to 1.0 to a hexadecimal representation of Red-Green-Blue colour.</p>
<pre><code>colour = (d, attribute) -&gt;
  red = Math.floor( (1-d[attribute])*255 ).toString 16
  blue = Math.floor( d[attribute]*255   ).toString 16
  red = &quot;0#{red}&quot; if red.length is 1
  blue = &quot;0#{blue}&quot; if blue.length is 1 
  &quot;##{red}00#{blue}&quot;</code></pre>
<p>To display students and indicate school enrolment by student proximity, we create a Gaussian overlay so all students in the same school clump together. Each student is assigned a randomised position centred on their school.</p>
<pre><code>render = (simulation) -&gt;
  simulation.schools.map (school) -&gt;
    school.x = width * (0.3 + 0.5 * school.id)
    school.y = height * 0.6
  simulation.students.map (student) -&gt;
    student.x = gausian(width/1.2) + student.school.x
    student.y = gausian(height/0.5) + student.school.y

gausian = (range) -&gt;
  Math.random()*range/8 + Math.random()*range/8 + Math.random()*range/8 - range/4</code></pre>
<p>Finally, we trigger the various simulations outlined in the article once all the scripts have loaded.</p>
<pre><code>window.onload = () -&gt;
  display &#39;sanity-check-1&#39;, sanity_check_1
  display &#39;sanity-check-2&#39;, sanity_check_2
  display &#39;shifting-averages&#39;, shifting_averages
  display &#39;relative-1&#39;, relative_1
  display &#39;relative-2&#39;, relative_2
  display &#39;head-start-1&#39;, head_start_1
  display &#39;head-start-2&#39;, head_start_2</code></pre>
<div class="references">
<h2 id="bibliography" class="unnumbered">Bibliography</h2>
<p>Adolphus, Katie, Clare L Lawton, and Louise Dye. 2013. โThe Effects of Breakfast on Behavior and Academic Performance in Children and Adolescents.โ <em>Frontiers in Human Neuroscience</em> 7. Frontiers Media SA.</p>
<p>Bronfenbrenner, Urie. 1994. โEcological Models of Human Development.โ <em>Readings on the Development of Children</em> 2. Freeman New York: 37โ43.</p>
<p>Caro, Daniel H, James Ted McDonald, and J Douglas Willms. 2009. โSocio-Economic Status and Academic Achievement Trajectories from Childhood to Adolescence.โ <em>Canadian Journal of Education/Revue Canadienne de Lโรฉducation</em> 32 (3). JSTOR: 558โ90.</p>
<p>Coleman, James S, and Nancy L Karweit. 1970. <em>Measures of School Performance</em>. Rand.</p>
<p>Dunn, Lloyd M, Leota M Dunn, Stephan Bulheller, and Hartmut H<span>รค</span>cker. 1965. <em>Peabody Picture Vocabulary Test</em>. American Guidance Service Circle Pines, MN.</p>
<p>Ehrenberg, Ronald G, Dominic J Brewer, Adam Gamoran, and J Douglas Willms. 2001. โClass Size and Student Achievement.โ <em>Psychological Science in the Public Interest</em>. JSTOR, 1โ30.</p>
<p>Hanushek, Eric A, John F Kain, Jacob M Markman, and Steven G Rivkin. 2003. โDoes Peer Ability Affect Student Achievement?โ <em>Journal of Applied Econometrics</em> 18 (5). Wiley Online Library: 527โ44.</p>
<p>Hume, David. 1748. <em>An Enquiry Concerning Human Understanding</em>.</p>
<p>Knuth, Donald Ervin. 1984. โLiterate Programming.โ <em>The Computer Journal</em> 27 (2). Br Computer Soc: 97โ111.</p>
<p>Kosgei, Anita, Jairo Kirwa Mise, Odhiambo Odera, and Mary Evelyn Ayugi. 2013. โInfluence of Teacher Characteristics on Studentsโ Academic Achievement Among Secondary Schools.โ <em>Journal of Education and Practice</em> 4 (3): 76โ82.</p>
<p>Lavin, David E. 1965. โThe Prediction of Academic Performance.โ Russel Sage Found.</p>
<p>NAPLAN. 2015. โWhy NAP.โ <a href="http://www.nap.edu.au/about/why-nap.html" class="uri">http://www.nap.edu.au/about/why-nap.html</a>.</p>
<p>Nghiem, Hong Son, Ha Trong Nguyen, Rasheda Khanam, and Luke B Connelly. 2015. โDoes School Type Affect Cognitive and Non-Cognitive Development in Children? Evidence from Australian Primary Schools.โ <em>Labour Economics</em> 33. Elsevier: 55โ65.</p>
<p>Pintrich, Paul R, and Elisabeth V De Groot. 1990. โMotivational and Self-Regulated Learning Components of Classroom Academic Performance.โ <em>Journal of Educational Psychology</em> 82 (1). American Psychological Association: 33.</p>
<p>Statistics, Australian Bureau of. 2014. <em>4221.0 - Schools, Australia, 2014 Dataset</em>. <a href="http://www.abs.gov.au/AUSSTATS/abs@.nsf/Lookup/4221.0Main+Features12014?OpenDocument" class="uri">http://www.abs.gov.au/AUSSTATS/abs@.nsf/Lookup/4221.0Main+Features12014?OpenDocument</a>.</p>
<p>Thrupp, Martin. 1995. โThe School Mix Effect: The History of an Enduring Problem in Educational Research, Policy and Practice.โ <em>British Journal of Sociology of Education</em> 16 (2). Taylor &amp; Francis: 183โ203.</p>
<p>โโโ. 1999. <em>Schools Making a Difference: School Mix, School Effectiveness, and the Social Limits of Reform</em>. McGraw-Hill Education (UK).</p>
<p>Thrupp, Martin, and Ruth Lupton. 2006. โTAKING SCHOOL CONTEXTS MORE SERIOUSLY: THE SOCIAL JUSTICE CHALLENGE.โ <em>British Journal of Educational Studies</em> 54 (3). Blackwell Publishing Ltd: 308โ28. doi:<a href="http://dx.doi.org/10.1111/j.1467-8527.2006.00348.x">10.1111/j.1467-8527.2006.00348.x</a>.</p>
<p>Wechsler, David. 2003. โWechsler Intelligence Scale for ChildrenโFourth Edition (WISC-IV).โ <em>San Antonio, TX: The Psychological Corporation</em>.</p>
<p>Zubrick, SR, SR Silburn, AA Williams, and G Vimpani. 2000. โIndicators of Social and Family Functioning: Final Report.โ Commonwealth Department of Family and Community Services, Canberra. Available at http://www. facs. gov. au/internet/facsin ternt. nsfl aboutfac si programs/families/isff. htm,[2000, 6 Sept.].</p>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I use the term <em>school performance</em> here to broadly describe the causal impact that pedagogy, education policy, or even build environment has on student acheivement.<a href="#fnref1">โฉ</a></p></li>
<li id="fn2"><p>Again, the claim is not that schooling is the only causal factor in student performance in the <em>real world</em>, but that it is the only causal factor in the model because it has been programmed as such.<a href="#fnref2">โฉ</a></p></li>
</ol>
</section>
</body>
</html>